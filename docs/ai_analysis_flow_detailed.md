# Детальный разбор AI-анализа организации: с очередью и без очереди

Этот документ описывает полный жизненный цикл анализа организации в текущем сервисе.
Важно: сам сервис `ai-site-analyzer` **stateless** — он не подключается к БД, не хранит
состояние задач и не управляет очередью напрямую. Очередь (если нужна) организуется
внешним оркестратором/downstream-сервисом.

## 1) Что делает сервис анализа и чего не делает

### Делает
- Принимает текст сайта и (опционально) каталоги товаров/оборудования.
- Формирует промпт и вызывает OpenAI Chat Completions.
- Парсит ответ по секциям (`DESCRIPTION`, `PRODCLASS`, `GOODS_TYPE`, и т.д.).
- Валидирует и при необходимости корректирует `PRODCLASS` через эмбеддинги.
- Векторизует описание и сопоставляет товары/оборудование с каталогами.
- Возвращает готовый `db_payload` для downstream-записи.

### Не делает
- Не читает и не пишет в БД самостоятельно.
- Не ставит задачи в очередь самостоятельно.
- Не выполняет retry на уровне очереди (это зона внешнего сервиса).

## 2) Вход и базовая валидация

Эндпоинт: `POST /v1/analyze/json`.

1. Сервис получает `AnalyzeFromJsonRequest`.
2. Проверяет, что `text_par` не пустой. Если пустой -> `HTTP 400`.
3. Выбирает `chat_model` и `embed_model`: сначала из запроса, иначе из настроек.
4. Если любая из моделей пуста -> `HTTP 400`.
5. Нормализует каталоги `goods_catalog` / `equipment_catalog`:
   - принимает list,
   - принимает объект `{ "items": [...] }`,
   - нормализует вектор каждого элемента (массив, literal-строка или `CatalogVector`).

Если каталог не передан, анализ продолжается, но матчинг по ID будет ограничен:
сервис вернёт сырые позиции из LLM и эмбеддинги этих позиций.

## 3) Основной AI-пайплайн (внутри одного запроса)

### Шаг 1. Построение промпта

- Вызывается `build_prompt(text_par)`.
- В промпт вставляется справочник `IB_PRODCLASS`.
- Ожидается строгий шаблон ответа с секциями в квадратных скобках.

Если промпт построен — пайплайн продолжает работу; отдельной ошибки на этом шаге
обычно не возникает, кроме системных исключений.

### Шаг 2. Вызов LLM

- Вызывается `call_openai_with_usage(prompt, chat_model)`.
- К OpenAI отправляется системное сообщение со строгим форматом ответа.
- Возвращается `answer` + usage (`input_tokens`, `output_tokens`).

Если `answer` пустой -> `HTTP 502` (пустой ответ LLM).

### Шаг 3. Парсинг ответа LLM

- Вызывается `parse_openai_answer(answer, text_par, embed_model)`.
- Извлекаются секции:
  - `DESCRIPTION`
  - `DESCRIPTION_SCORE` (опц.)
  - `PRODCLASS`
  - `PRODCLASS_SCORE` (опц.)
  - `EQUIPMENT_SITE`
  - `GOODS`
  - `GOODS_TYPE`
  - `OKVED_SCORE` (опц.)

Если обязательная секция не найдена или структура невалидна:
- ошибка парсинга -> `HTTP 502`.

### Шаг 4. Разрешение `PRODCLASS`

Алгоритм приоритета:
1. Пробуем извлечь ID цифрами из `[PRODCLASS]`.
2. Если не получилось — пытаемся сопоставить по названию (`name_match`).
3. Если не получилось — fallback по эмбеддингам текста сайта (`text_embedding_fallback`).
4. Если LLM дал ID, но эмбеддинги уверенно показывают другой класс
   (порог/дельта), делается override (`text_embedding_override`).

`PRODCLASS_SCORE` берётся так:
- из ответа модели, если корректный;
- иначе из эмбеддингов (`text_embedding_verify`/`override`/`fallback`);
- иначе попытка пересчёта fallback-эмбеддингами;
- иначе `0.0` + `PRODCLASS_SCORE_SOURCE=not_available` и `PRODCLASS_SCORE_ERROR`.

### Шаг 5. Эмбеддинг описания

- Если `DESCRIPTION` не пустой, строится эмбеддинг `description_vector`.
- Если не удалось построить эмбеддинг — ошибка логируется, но запрос не падает;
  `description_vector` становится пустым.

### Шаг 6. Подготовка списков товаров/оборудования

- `GOODS_TYPE_LIST` берётся из `[GOODS_TYPE]`.
- Если `[GOODS_TYPE]` пустой, но есть `[GOODS]`, используется fallback:
  `GOODS_TYPE_LIST = GOODS_LIST`, `GOODS_TYPE_SOURCE=GOODS`.
- Для оборудования используется `EQUIPMENT_LIST`.
- Списки очищаются от дублей и пустых/маркеров вроде `нет`, `—`, `n/a`.

### Шаг 7. Enrichment по каталогам

Для `GOODS_TYPE_LIST` и `EQUIPMENT_LIST` отдельно:
1. Строятся эмбеддинги элементов списка.
2. Для каждого элемента каталога:
   - если есть `vec` (literal pgvector) -> используем его;
   - иначе берём LRU-кэш вектора по `(embed_model, name)`;
   - иначе считаем эмбеддинг имени каталога.
3. Считается cosine similarity item ↔ catalog.
4. Нормализуется в score [0..1].
5. Если score ниже порога (`0.45`) -> `match_id=null`, `score=null`.

Если каталог пустой, сервис всё равно возвращает элементы с их эмбеддингами,
но без `match_id`.

### Шаг 8. Формирование ответа

В ответе собираются:
- `parsed` (включая диагностику и превью будущих строк `AI_SITE_*`),
- `prodclass`,
- `description_vector`,
- `goods_items`, `equipment_items`,
- `counts`, `timings`, `catalogs`,
- `request_cost` (по usage + прайсинг-модели),
- `billing_summary` (если доступен org costs API),
- `db_payload` для записи downstream.

Если billing API недоступен, это **не ломает** анализ: `billing_summary=null`.

## 4) Сценарий «без очереди» (синхронный вызов)

Это прямой режим:
1. Клиент вызывает `POST /v1/analyze/json`.
2. Ждёт ответ в том же HTTP-запросе.
3. Получает `db_payload`.
4. Сам записывает данные в БД (или другое хранилище).

Особенности:
- Минимальная задержка между вызовом и результатом.
- Проще отлаживать (trace одного запроса).
- Риски: долгий ответ при пиковых нагрузках и необходимость внешнего retry.

## 5) Сценарий «с очередью» (оркестратор с job processing)

Так как сервис stateless, очередь организуется внешним компонентом
(например, worker + broker + БД задач).

Типовой поток:

1. **Producer** кладёт задачу в очередь
   - `task_id`, `pars_id`, `company_id`, `text_par`, (опц.) каталоги,
     лимит retry, дедлайн.
2. **Worker** забирает задачу
   - переводит в статус `processing`.
3. **Worker** вызывает `/v1/analyze/json`
   - передаёт все необходимые данные в теле запроса.
4. **Получает ответ**
   - при `200` проверяет контракт (`db_payload` обязателен).
5. **Запись результата**
   - в транзакции обновляет целевые таблицы и фиксирует `done`.
6. **Обработка ошибок**
   - `4xx`: обычно `failed_no_retry` (ошибка входа),
   - `5xx`/timeout/network: retry по backoff,
   - исчерпан retry -> `failed`/dead-letter/manual review.

Рекомендуемая политика retry:
- максимум 3 попытки для сетевых/5xx ошибок;
- экспоненциальный backoff;
- отсутствие повторов для 4xx без изменения входных данных.

## 6) Куда сервис обращается и что ищет

Внутренние/внешние зависимости в рантайме:

1. **OpenAI Chat Completions**
   - цель: получить структурированный ответ по шаблону.
2. **OpenAI Embeddings**
   - цель: векторизация описания, товаров/оборудования,
     верификация/резерв по `PRODCLASS`.
3. **OpenAI Costs API (опционально)**
   - цель: MTD сводка расходов для `billing_summary`.

Что ищем в данных:
- в `[PRODCLASS]` — валидный ID класса;
- в `[GOODS_TYPE]`/`[GOODS]`/`[EQUIPMENT_SITE]` — перечни сущностей;
- в каталогах — лучший match по cosine similarity;
- в fallback-логике — рабочий источник скора и классификации.

## 7) Что происходит, если что-то не найдено

- Пустой `text_par` -> `HTTP 400`.
- Нет моделей (`chat_model`/`embed_model`) -> `HTTP 400`.
- LLM вернул пусто -> `HTTP 502`.
- Не распарсились обязательные секции -> `HTTP 502`.
- `PRODCLASS` не удалось взять из ответа:
  - пробуем `name_match`,
  - потом эмбеддинг fallback,
  - если и это не сработало — ошибка парсинга.
- Нет `PRODCLASS_SCORE`:
  - пробуем `final_score` эмбеддингов,
  - пробуем fallback-пересчёт,
  - иначе `0.0` + `not_available`.
- Пустой/неполный каталог:
  - возвращаем элементы без `match_id` (или с `null` score),
  - сам анализ не падает.
- Не удалось billing summary:
  - лог warning,
  - `billing_summary=null`, остальной ответ полноценный.

## 8) Результат для downstream

Главный артефакт — `db_payload`:
- `description` + `description_vector`,
- `prodclass`,
- `goods_types`, `equipment`,
- `llm_answer`.

То есть при любом режиме (очередь/без очереди) контракт анализа один и тот же;
разница только в том, **кто** управляет retries, статусами и записью в БД:
- без очереди — вызывающий клиент;
- с очередью — внешний оркестратор/worker.
