# Как сервис определяет класс производства

Документ описывает цепочку принятия решения по полю `PRODCLASS` и сопровождающим
его диагностическим атрибутам. Все шаги реализованы в
`app/services/analyzer.py` и задокументированы ниже, чтобы при отладке было
проще понять, откуда берётся тот или иной результат.

## 1. Общая схема

1. **Чтение ответа LLM.** Из секции `[PRODCLASS]` пытаемся получить ID и
   исходный скор. Парсинг реализован в `parse_openai_answer`.
2. **Приведение ID к справочнику.** Вначале достаём число напрямую из текста, а
   затем ищем совпадение по названию, если число отсутствует или вне справочника.
   Эти шаги выполняет `_resolve_prodclass_id`.
3. **Проверка эмбеддингами.** Даже если LLM вернул ID, сервис дополнительно
   строит эмбеддинг текста сайта и сравнивает его с названиями всех классов.
   Результат сравнения используется как резервный источник или для переопределения
   ответа модели.
4. **Заполнение диагностических полей.** В `parsed` сохраняются как итоговый
   `PRODCLASS`, так и вспомогательные значения (`PRODCLASS_SOURCE`,
   `PRODCLASS_EMBED_GUESS`, `PRODCLASS_SCORE_SOURCE` и др.).

## 2. Детали определения ID

* Сначала выполняется `_parse_prodclass_id_from_digits` — берём первое число,
  которое есть в справочнике `ib_prodclass`. Если оно найдено, источник помечается
  как `model_reply`.【F:app/services/analyzer.py†L450-L456】【F:app/services/analyzer.py†L495-L501】
* Если числа нет, используем `_guess_prodclass_by_name`: сравниваем нормализованное
  название из секции с названиями из справочника. При успехе источник становится
  `name_match`.【F:app/services/analyzer.py†L458-L462】
* Когда и цифры, и имя не помогли, берём лучший результат по эмбеддингам текста
  сайта. В этом случае `PRODCLASS_SOURCE` получает значение
  `text_embedding_fallback`, а сам ID и скор берутся из эмбеддинг-анализа.
  【F:app/services/analyzer.py†L464-L474】

## 3. Когда ответ LLM переопределяется

Даже после того как LLM прислал число, сервис проверяет его эмбеддингами:

* Строится вектор сайта и вычисляется схожесть с классом, который указал LLM.
  Это значение хранится как `final_score` и используется для проверки или
  последующего пересчёта скора.【F:app/services/analyzer.py†L478-L483】
* Если эмбеддинги подсказывают другой класс и при этом:
  * скор альтернативы ≥ 0.55; и
  * он как минимум на 0.1 выше скора текущего ответа —
  то сервис заменит `PRODCLASS` на эмбеддинг-предсказание. Источник меняется на
  `text_embedding_override`, а в `PRODCLASS_EMBED_GUESS` и
  `PRODCLASS_EMBED_GUESS_SCORE` пишутся значения лучшей альтернативы.
  【F:app/services/analyzer.py†L485-L494】【F:app/services/analyzer.py†L528-L538】

## 4. Как высчитывается `PRODCLASS_SCORE`

1. Если LLM прислал валидный скор и не было переопределения по эмбеддингам —
   сохраняем его как `model_reply`.
2. Если LLM прислал ID, но скор отсутствует, а эмбеддинги доступны, то берём
   `final_score`, рассчитанный в ходе проверки, и помечаем источник как
   `text_embedding_verify`.
3. Когда ответ LLM был переопределён, скор также берётся из эмбеддинг-анализа,
   а источник равен `text_embedding_override` или `text_embedding_fallback` — в
   зависимости от сценария.
4. Если эмбеддинги недоступны, сервис пытается посчитать скор «с нуля» по паре
   «текст сайта ↔ название класса». Успешный результат обозначается как
   `fallback_embeddings`.
5. Любая ошибка или отсутствие модели эмбеддингов приводит к `not_available` и
   значению `0.0`, при этом текст ошибки возвращается в
   `PRODCLASS_SCORE_ERROR` для последующего анализа.
   【F:app/services/analyzer.py†L540-L585】

## 5. Как читать диагностику

* `PRODCLASS_SOURCE` — источник ID (`model_reply`, `name_match`,
  `text_embedding_override`, `text_embedding_fallback`).
* `PRODCLASS_EMBED_GUESS` и `PRODCLASS_EMBED_GUESS_SCORE` — лучшая подсказка
  эмбеддингов. Если они отличаются от финального ID, это повод проверить логику
  ответа LLM.
* `PRODCLASS_SCORE_SOURCE` — откуда взялся финальный скор (см. перечисление выше).
* `PRODCLASS_SCORE_ERROR` — текст ошибки, если скор восстановить не удалось.

Используйте эти поля при отладке и мониторинге: они позволяют понять, насколько
часто модель ошибается и в каких случаях эмбеддинги помогают скорректировать
результат.
