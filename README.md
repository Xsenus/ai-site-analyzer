# AI Site Analyzer

AI Site Analyzer — это асинхронный сервис на FastAPI, который анализирует сайты и
возвращает структурированный отчёт. Приложение больше не подключается к базам
данных: всё состояние передаётся в запросе и возвращается в ответе. Сервис
использует OpenAI для генерации отчётов и эмбеддингов и предоставляет
вспомогательный эндпоинт `/api/ai-search` для получения векторных
представлений текстов.

## Основные возможности

- **Анализ сайтов без доступа к БД.** Основной эндпоинт `/v1/analyze/json`
  реализован в `app/api/handlers/analyze_json.py` и возвращает
  структурированный отчёт вместе с готовым `db_payload` для downstream-сервисов.
- **Полностью stateless-архитектура.** Больше нет соединений с PostgreSQL —
  сервис работает только с входными данными и возвращает результат в ответе.
- **Интеграция с OpenAI.** Модуль `app/services/analyzer.py` собирает промпт,
  вызывает LLM и разбирает ответ, а `app/services/embeddings.py` отвечает за
  получение эмбеддингов (внутренний сервис → OpenAI fallback).
- **Сервис эмбеддингов `/api/ai-search`.** Реализован в
  `app/routers/ai_search.py`, включает простой rate limit, нормализацию запросов
  и возможность подключить внутренний провайдер эмбеддингов.
- **Единая конфигурация через `.env`.** Настройки описаны в `app/config.py` и
  автоматически нормализуются (алиасы, значения по умолчанию, computed-поля).

## Структура проекта

```text
app/
├── api/                # публичные REST-роуты и pydantic-схемы
├── models/             # справочники/модели домена
├── routers/            # дополнительные роутеры (ai-search)
├── schemas/            # pydantic-схемы для ai-search
├── services/           # интеграция с OpenAI, логика анализа
├── utils/              # вспомогательные утилиты (rate limiter и др.)
├── config.py           # pydantic Settings для загрузки окружения
├── logging_setup.py    # базовая настройка логирования
└── main.py             # точка входа FastAPI-приложения
```

## Подготовка окружения

1. **Python.** Требуется Python 3.11+.
2. **Зависимости.** Установите пакеты: `pip install -r requirements.txt`.
3. **Переменные окружения.** Скопируйте пример и укажите свои значения:
   ```bash
   cp .env.example .env
   ```
   Минимальный набор — ключ OpenAI. Полный список переменных приведён ниже.
4. **Запуск.** Используйте любой из вариантов:
```bash
# режим разработки с авто-перезапуском
UVICORN_RELOAD=1 python -m app.run

# продакшн-запуск без перезапуска кода
python -m app.run

# или напрямую через uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8090
```

Для продакшна важно оставить `reload` выключенным, иначе uvicorn запускает
дополнительный наблюдающий процесс, который убивает воркеры при высокой нагрузке
или изменении файлов. Количество воркеров можно настроить переменной
`UVICORN_WORKERS` (по умолчанию 1).

После запуска основное приложение доступно на `http://localhost:8090`.

## Ключевые переменные `.env`

| Переменная | Назначение |
| --- | --- |
| `OPENAI_API_KEY` | Ключ OpenAI для генерации отчётов и эмбеддингов. |
| `CHAT_MODEL` | Модель диалога для анализа (по умолчанию `gpt-4o`). |
| `OPENAI_EMBED_MODEL` | Модель эмбеддингов (по умолчанию `text-embedding-3-large`). |
| `INTERNAL_EMBED_URL` | URL внутреннего сервиса эмбеддингов (опционально). |
| `AI_SEARCH_TIMEOUT` | Таймаут `POST /api/ai-search` в секундах. |
| `AI_SEARCH_RATE_LIMIT_PER_MIN` | Лимит запросов `/api/ai-search` в минуту. |
| `CORS_ALLOW_*` | Настройки CORS (origins, methods, headers, credentials). |
| `LOG_LEVEL` | Уровень логирования FastAPI-приложения. |

Дополнительные параметры (например, `VECTOR_DIM`, `EMBED_BATCH_SIZE`,
`EMBED_MAX_CHARS`, `DEBUG_OPENAI_LOG`) можно оставить по умолчанию или
переопределить при необходимости.

## Проверка работоспособности

- `GET /health` — простая проверка доступности сервиса.
- `POST /v1/analyze/json` — запуск анализа без прямого доступа к БД.
- `POST /api/ai-search` — получение эмбеддинга или fallback-ответов.

## Работа с результатами анализа

Эндпоинт `POST /v1/analyze/json` не пишет данные в БД самостоятельно. Вместо
этого он возвращает детальный JSON с блоком `db_payload`, который повторяет
структуру таблиц (`ai_site_prodclass`, `ai_site_goods_types`, `ai_site_equipment`
и др.) и может быть напрямую использован downstream-сервисом. В ответе также
присутствуют `counts`, `timings`, предпросмотры записей и исходный ответ модели —
это помогает валидировать вставки и строить мониторинг.

Дополнительные детали контракта и примеры интеграции приведены в документации:

- [Контракт сервиса анализа с downstream-записью](docs/analyze_json_downstream_contract.md)
- [Рекомендации по интеграции `/v1/analyze/json`](docs/analyze_json_integration.md)

## Полезные советы

- Логирование уже настроено в `app/logging_setup.py`. При необходимости
  используйте переменную `LOG_LEVEL` или переопределите формат.
- В продакшене стоит подключить внешнее управление секретами (Vault, AWS Secrets
  Manager и т.д.) и настроить аудит вызовов.
- Для локальной разработки достаточно сконфигурировать переменные окружения и
  при необходимости подготовить хранилище, куда downstream-сервис будет писать
  `db_payload`.
