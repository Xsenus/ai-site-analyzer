# AI Site Analyzer

AI Site Analyzer — асинхронный сервис на FastAPI, который анализирует сайты и
возвращает структурированный отчёт. Приложение работает полностью stateless:
всё состояние передаётся в запросе и возвращается в ответе, поэтому подключение
к базам данных не требуется. Сервис использует OpenAI для генерации отчётов и
эмбеддингов и предоставляет вспомогательный эндпоинт `/api/ai-search` для
получения векторных представлений текстов.

## Основные возможности

- **Анализ сайтов без доступа к БД.** Основной эндпоинт `/v1/analyze/json`
  реализован в `app/api/handlers/analyze_json.py` и возвращает
  структурированный отчёт вместе с готовым `db_payload` для downstream-сервисов.
- **Полностью stateless-архитектура.** Сервис работает только с входными
  данными и возвращает результат в ответе — соединений с базами данных нет.
- **Интеграция с OpenAI.** Модуль `app/services/analyzer.py` собирает промпт,
  вызывает LLM и разбирает ответ, а `app/services/embeddings.py` отвечает за
  получение эмбеддингов (внутренний сервис → OpenAI fallback).
- **Сервис эмбеддингов `/api/ai-search`.** Реализован в
  `app/routers/ai_search.py`, включает простой rate limit, нормализацию запросов
  и возможность подключить внутренний провайдер эмбеддингов.
- **Генерация промптов для отладки.** Эндпоинты `/v1/prompts/site-available` и
  `/v1/prompts/site-unavailable` возвращают сформированный промпт, ответ модели
  и телеметрию этапов, что помогает тестировать шаблоны без полного пайплайна.
- **Единая конфигурация через `.env`.** Настройки описаны в `app/config.py` и
  автоматически нормализуются (алиасы, значения по умолчанию, computed-поля).

## Структура проекта

```text
app/
├── api/                # публичные REST-роуты и pydantic-схемы
├── models/             # справочники/модели домена
├── routers/            # дополнительные роутеры (ai-search, prompts)
├── schemas/            # pydantic-схемы
├── services/           # интеграция с OpenAI, логика анализа, эмбеддинги
├── utils/              # вспомогательные утилиты (rate limiter и др.)
├── config.py           # pydantic Settings для загрузки окружения
├── logging_setup.py    # базовая настройка логирования
└── main.py             # точка входа FastAPI-приложения
```

## Быстрый старт

1. **Python.** Требуется Python 3.11+.
2. **Зависимости.** Установите пакеты: `pip install -r requirements.txt`.
3. **Переменные окружения.** Скопируйте пример и укажите свои значения:
   ```bash
   cp .env.example .env
   ```
   Минимальный набор — ключ OpenAI. Полный список переменных приведён ниже.
4. **Запуск.** Для локальной разработки удобно использовать Uvicorn:
   ```bash
   uvicorn app.main:app --host 0.0.0.0 --port 8090 --reload
   ```
   В продакшене предпочтительнее запуск через наш раннер, чтобы единообразно
   управлять воркерами и параметрами перезапуска:
   ```bash
   python -m app.run
   ```

После запуска основное приложение доступно на `http://localhost:8090`.

## Обзор API

| Маршрут | Назначение | Документация |
| --- | --- | --- |
| `GET /health` | Простой health-check. | — |
| `POST /v1/analyze/json` | Основной анализ сайта, возвращает `db_payload` и телеметрию. | [Контракт](docs/analyze_json_downstream_contract.md), [Интеграция](docs/analyze_json_integration.md) |
| `POST /v1/prompts/site-available` | Отладочный маршрут: строит промпт по тексту сайта и вызывает LLM. | [Промпты](docs/prompt_templates.md) |
| `POST /v1/prompts/site-unavailable` | Отладочный маршрут для случая, когда доступен только ОКВЭД. | [Промпты](docs/prompt_templates.md) |
| `POST /api/ai-search` | Получение эмбеддинга или fallback-ответов при матчинге текстов. | [AI Search](docs/ai_search.md) |

OpenAPI-спека доступна по `/docs` после запуска сервиса.

## Переменные окружения раннера

Модуль `app.run` поддерживает переменные окружения для настройки Uvicorn без
изменения командной строки:

| Переменная | Назначение | Значение по умолчанию |
| --- | --- | --- |
| `HOST` | Адрес привязки сервера | `0.0.0.0` |
| `PORT` | Порт HTTP | `8090` |
| `WORKERS` | Количество воркеров Uvicorn | `1` |
| `UVICORN_RELOAD` | Горячая перезагрузка при изменении файлов | `false` |

> ⚠️ При включённом `UVICORN_RELOAD` Uvicorn ограничивает количество воркеров до
> одного. Раннер автоматически приведёт `WORKERS` к `1`, если вы включили
> перезагрузку.

## Ключевые переменные `.env`

| Переменная | Назначение |
| --- | --- |
| `OPENAI_API_KEY` | Ключ OpenAI для генерации отчётов и эмбеддингов. |
| `CHAT_MODEL` | Модель диалога для анализа (по умолчанию `gpt-4o`). |
| `OPENAI_EMBED_MODEL` | Модель эмбеддингов (по умолчанию `text-embedding-3-large`). |
| `INTERNAL_EMBED_URL` | URL внутреннего сервиса эмбеддингов (опционально). |
| `AI_SEARCH_TIMEOUT` | Таймаут `POST /api/ai-search` в секундах. |
| `AI_SEARCH_RATE_LIMIT_PER_MIN` | Лимит запросов `/api/ai-search` в минуту. |
| `CORS_ALLOW_*` | Настройки CORS (origins, methods, headers, credentials). |
| `LOG_LEVEL` | Уровень логирования FastAPI-приложения. |

Дополнительные параметры (например, `VECTOR_DIM`, `EMBED_BATCH_SIZE`,
`EMBED_MAX_CHARS`, `DEBUG_OPENAI_LOG`) можно оставить по умолчанию или
переопределить при необходимости.

## Как устроена обработка запросов

- **Анализ сайта `/v1/analyze/json`.** Обработчик нормализует каталоги,
  строит промпт, вызывает LLM и дополняет ответ эмбеддингами. Результат
  возвращается в одном JSON с секциями `parsed`, `counts`, `timings` и
  готовым `db_payload` для записи downstream-сервисом.
- **Эмбеддинги `/api/ai-search`.** Запросы проходят через sliding-window
  rate-limit, текст нормализуется, далее вызывается внутренний провайдер
  эмбеддингов или OpenAI в качестве fallback. Если вектор не получен,
  возвращаются пустые коллекции ID/списков, что можно заменить своей
  логикой ранжирования.
- **Промпты `/v1/prompts/*`.** Эндпоинты собирают шаблон, вызывают OpenAI и
  возвращают промпт, ответ и подробные события пайплайна. Они удобны для
  тестирования промптов и проверки длины/структуры без привязки к записи в БД.

## Проверка работоспособности

- `GET /health` — быстрая проверка доступности сервиса.
- `POST /v1/analyze/json` — запуск анализа без прямого доступа к БД.
- `POST /api/ai-search` — получение эмбеддинга или fallback-ответов.

## Работа с результатами анализа

Эндпоинт `POST /v1/analyze/json` не пишет данные в БД самостоятельно. Вместо
этого он возвращает детальный JSON с блоком `db_payload`, который повторяет
структуру таблиц (`ai_site_prodclass`, `ai_site_goods_types`, `ai_site_equipment`
и др.) и может быть напрямую использован downstream-сервисом. В ответе также
присутствуют `counts`, `timings`, предпросмотры записей и исходный ответ модели —
это помогает валидировать вставки и строить мониторинг.

Дополнительные детали контракта и примеры интеграции приведены в документации:

- [Контракт сервиса анализа с downstream-записью](docs/analyze_json_downstream_contract.md)
- [Рекомендации по интеграции `/v1/analyze/json`](docs/analyze_json_integration.md)
- [Генерация промптов OpenAI](docs/prompt_templates.md)
- [AI Search: получение эмбеддингов и fallback-ответов](docs/ai_search.md)

## Полезные советы

- Логирование уже настроено в `app/logging_setup.py`. При необходимости
  используйте переменную `LOG_LEVEL` или переопределите формат.
- В продакшене стоит подключить внешнее управление секретами (Vault, AWS Secrets
  Manager и т.д.) и настроить аудит вызовов.
- Для локальной разработки достаточно сконфигурировать переменные окружения и
  при необходимости подготовить хранилище, куда downstream-сервис будет писать
  `db_payload`.
- Для деплоя под systemd можно использовать пример юнита из
  [`docs/systemd-service.md`](docs/systemd-service.md). Он запускает `app.run`
  и позволяет управлять воркерами через переменные окружения без изменения
  ExecStart.
